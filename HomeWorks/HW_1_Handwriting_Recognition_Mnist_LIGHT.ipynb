{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_1_Handwriting_Recognition_Mnist_LIGHT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_r2OZPNinfy",
        "colab_type": "text"
      },
      "source": [
        "# Light. Version 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neKOciiDiFzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential # class of model\n",
        "from tensorflow.keras.layers import Dense # fullconnected layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.preprocessing import image # for add image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import output\n",
        "import seaborn as sns\n",
        "import pylab\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDFrziWGomIq",
        "colab_type": "code",
        "outputId": "64c64f19-2861-40f9-9759-4830f4cf2b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "model = Sequential() # make neuralnetwork\n",
        "model.add(Dense(800, input_dim = 784, activation='relu'))\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 800)               628000    \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 400)               320400    \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 10)                4010      \n",
            "=================================================================\n",
            "Total params: 952,410\n",
            "Trainable params: 952,410\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pinZMA-FNL6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZknSZgXENanQ",
        "colab_type": "code",
        "outputId": "b4069cd7-da2e-4223-e3bf-e458337444ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSNxAM_Iyt1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize data\n",
        "x_train = x_train.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test.astype('float32')\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeQ5wcMSN2UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP38mZpevBpE",
        "colab_type": "code",
        "outputId": "ad65cd64-df8d-4293-db74-49b6b9cd8c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=128, epochs=15, verbose=1)\n",
        "# verbose = visualation progress"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "469/469 [==============================] - 7s 16ms/step - loss: 0.2061 - accuracy: 0.9389\n",
            "Epoch 2/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0767 - accuracy: 0.9766\n",
            "Epoch 3/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0485 - accuracy: 0.9840\n",
            "Epoch 4/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0356 - accuracy: 0.9886\n",
            "Epoch 5/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0266 - accuracy: 0.9915\n",
            "Epoch 6/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0198 - accuracy: 0.9935\n",
            "Epoch 7/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0202 - accuracy: 0.9933\n",
            "Epoch 8/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0153 - accuracy: 0.9950\n",
            "Epoch 9/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0126 - accuracy: 0.9960\n",
            "Epoch 10/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0127 - accuracy: 0.9958\n",
            "Epoch 11/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0109 - accuracy: 0.9967\n",
            "Epoch 12/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0126 - accuracy: 0.9957\n",
            "Epoch 13/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0123 - accuracy: 0.9961\n",
            "Epoch 14/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0064 - accuracy: 0.9979\n",
            "Epoch 15/15\n",
            "469/469 [==============================] - 7s 15ms/step - loss: 0.0081 - accuracy: 0.9975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f890571c160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2YLRF4_xEe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('model_base.h5')\n",
        "model.load_weights('model_base.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARjkX2XI4j4v",
        "colab_type": "code",
        "outputId": "d360cf80-b51f-46bc-c09e-18d31c6b4be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "res_base = model.evaluate(x_test, y_test, verbose=1)\n",
        "print(res_base)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1169 - accuracy: 0.9777\n",
            "[0.11694846302270889, 0.9776999950408936]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qRg_qsL9LG1",
        "colab_type": "text"
      },
      "source": [
        "# Light. Version 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPsureUBDHCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# repeat prepare data for convenience and stability\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test.astype('float32')\n",
        "x_test = x_test / 255\n",
        "y_train = utils.to_categorical(y_train, 10)\n",
        "y_test = utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IJ3E6Xz9KJC",
        "colab_type": "code",
        "outputId": "d7f2f23e-309b-4a4c-9767-2bc4333f0215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 47
        }
      },
      "source": [
        "var_neu = pd.DataFrame(columns = ['n_hide_layer', 'act_func', 'batch_size', 'accuracy'])\n",
        "'''\n",
        "Для удобного анализа сделаем таблицу точности наших нейронных сетей.\n",
        "n_hide_layer - количество нейронов в единственном скрытом слое: 10, 100, 400 или 5000;\n",
        "(первый слой 800 нейронов, последний - 10)\n",
        "act_func - активационная функция в скрытом слое: relu или linear;\n",
        "batch_size - 1, 10, 128 или вся база (60000);\n",
        "'''\n",
        "var_neu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_hide_layer</th>\n",
              "      <th>act_func</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [n_hide_layer, act_func, batch_size, accuracy]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rec-f4TZBr5j",
        "colab_type": "code",
        "outputId": "d7d6f410-a2d9-4e67-f4a9-09e5ee671f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# checking if gpu works\n",
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnwpbvyXBHDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_nh = [10, 100, 400, 5000]\n",
        "list_af = ['relu', 'linear']\n",
        "list_bs = [1, 10, 128, 60000]\n",
        "i = 0 # not smart method for count index =)\n",
        "for nh in list_nh:\n",
        "  for af in list_af:\n",
        "    for bs in list_bs:\n",
        "      model = Sequential()\n",
        "      model.add(Dense(800, input_dim = 784, activation='relu'))\n",
        "      model.add(Dense(nh, activation=af))\n",
        "      model.add(Dense(10, activation='softmax'))\n",
        "      model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "      model.fit(x_train, y_train, batch_size=bs, epochs=15, verbose=0)\n",
        "      res_base = model.evaluate(x_test, y_test, verbose=0)\n",
        "      var_neu.loc[i] = [nh, af, bs, res_base[1]]\n",
        "      i += 1\n",
        "  # Play an audio beep and text-information.\n",
        "  print('Success nh:', nh)\n",
        "  output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yimw69lrtnn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_neu.to_csv('var_neu.csv')\n",
        "files.download(\"var_neu.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugL0n_LeJzlF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var_neu = pd.read_csv('var_neu.csv', index_col=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUzIi0vyXbPu",
        "colab_type": "code",
        "outputId": "b31ebdac-4555-47fa-eb49-8bc782227a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "var_neu.sort_values('accuracy', ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_hide_layer</th>\n",
              "      <th>act_func</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>5000</td>\n",
              "      <td>relu</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>100</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>400</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>100</td>\n",
              "      <td>linear</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>relu</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>linear</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>400</td>\n",
              "      <td>relu</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>400</td>\n",
              "      <td>relu</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>relu</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>400</td>\n",
              "      <td>linear</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>5000</td>\n",
              "      <td>linear</td>\n",
              "      <td>128</td>\n",
              "      <td>0.9762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>5000</td>\n",
              "      <td>relu</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100</td>\n",
              "      <td>linear</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>linear</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>400</td>\n",
              "      <td>linear</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>400</td>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>5000</td>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>5000</td>\n",
              "      <td>linear</td>\n",
              "      <td>10</td>\n",
              "      <td>0.9613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>5000</td>\n",
              "      <td>linear</td>\n",
              "      <td>1</td>\n",
              "      <td>0.9362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>5000</td>\n",
              "      <td>relu</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.9251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>5000</td>\n",
              "      <td>linear</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.9245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>400</td>\n",
              "      <td>linear</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.9138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>400</td>\n",
              "      <td>relu</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.9109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>100</td>\n",
              "      <td>linear</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.9014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>100</td>\n",
              "      <td>relu</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.8993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>linear</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.8444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10</td>\n",
              "      <td>relu</td>\n",
              "      <td>60000</td>\n",
              "      <td>0.6728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    n_hide_layer act_func  batch_size  accuracy\n",
              "6             10   linear         128    0.9831\n",
              "26          5000     relu         128    0.9826\n",
              "14           100   linear         128    0.9820\n",
              "22           400   linear         128    0.9818\n",
              "10           100     relu         128    0.9816\n",
              "13           100   linear          10    0.9811\n",
              "2             10     relu         128    0.9810\n",
              "5             10   linear          10    0.9809\n",
              "18           400     relu         128    0.9803\n",
              "9            100     relu          10    0.9789\n",
              "17           400     relu          10    0.9788\n",
              "1             10     relu          10    0.9786\n",
              "21           400   linear          10    0.9775\n",
              "30          5000   linear         128    0.9762\n",
              "25          5000     relu          10    0.9756\n",
              "12           100   linear           1    0.9755\n",
              "4             10   linear           1    0.9748\n",
              "20           400   linear           1    0.9721\n",
              "0             10     relu           1    0.9693\n",
              "16           400     relu           1    0.9642\n",
              "24          5000     relu           1    0.9630\n",
              "29          5000   linear          10    0.9613\n",
              "8            100     relu           1    0.9597\n",
              "28          5000   linear           1    0.9362\n",
              "27          5000     relu       60000    0.9251\n",
              "31          5000   linear       60000    0.9245\n",
              "23           400   linear       60000    0.9138\n",
              "19           400     relu       60000    0.9109\n",
              "15           100   linear       60000    0.9014\n",
              "11           100     relu       60000    0.8993\n",
              "7             10   linear       60000    0.8444\n",
              "3             10     relu       60000    0.6728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHb__1QWBzjr",
        "colab_type": "text"
      },
      "source": [
        "## Выводы.\n",
        "\n",
        "От количества нейронов время работы не так зависит, как от batch_size. Чем он меньше, тем дольше будет считаться нейронка.\n",
        "\n",
        "Этот же показатель оказался наиболее важным для качества нейросети, но здесь нету прямой корреляции, нельзя просто сделать их поменьше или побольше. Нужно подбирать значение. Но однозначно можно сказать, что брать всю выборку 60000 не есть гуд идея. \n",
        "\n",
        "Однако, я полагаю, что ключевой фактор может быть не столько сам параметр, сколько количество пересчетов весов, которые следуют за ним, если не менять количество эпох. Чтобы проверить этот факт, можно сделать тест, который будет менять batch_size и epochs таким образом, чтобы количество пересчетов оставалось равным. Извиняюсь если формулировки не совсем точные, не знаю как правильно называется перераспределение весов.\n",
        "\n",
        "Также интересным и неожиданным обстоятельством является преобладание результатов линейной функции над релу. 3 из 4 первых результата поставлены на моделях с 'linear'.\n",
        "\n",
        "Не знаю насколько это верное решение, я же только учусь. Но я предпочту для дальнейших исследований и экспериментов взять третью модель, а не первую. Дело в том, что во-первых разница между ними всего на 1 тысячную процента! Нейросеть номер один работает на 1\\100 000 лучше чем нейросеть три! У нас же тут не Kaggle, чтобы бороться за такие цифры) при этом тестовая выборка, это всего-лишь выборка, конечная цель, чтобы нейросеть лучше определяла новые рукописные цифры. А количество нейронов 100, мне кажется дает больше возможносетй нейросети, чем 10. Но это возможно ошибочные умозаключения. Всего не перепроверишь за время отведенное под домашнюю работу.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8isr0DrJKa3A",
        "colab_type": "code",
        "outputId": "aeb76858-324b-4534-8291-b45542d9de73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "count = int(60000/128*15)\n",
        "list_bs = [128, 128*6, 128*30, 60000]\n",
        "for bs in list_bs:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(800, input_dim = 784, activation='relu'))\n",
        "  model.add(Dense(100, activation='linear'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.fit(x_train, y_train, batch_size=bs, epochs=int(count/(60000/bs)), verbose=0)\n",
        "  res_base = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print(f'nh = 100, af = \"linear\", bs = {bs}, epochs = {count/(60000/bs)}, accuracy = {res_base[1]}')\n",
        "print('Success!')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nh = 100, af = \"linear\", bs = 128, epochs = 14.999466666666667, accuracy = 0.9751999974250793\n",
            "nh = 100, af = \"linear\", bs = 768, epochs = 89.9968, accuracy = 0.9847000241279602\n",
            "nh = 100, af = \"linear\", bs = 3840, epochs = 449.984, accuracy = 0.9824000000953674\n",
            "nh = 100, af = \"linear\", bs = 60000, epochs = 7031.0, accuracy = 0.9799000024795532\n",
            "Success!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zLv2jYRWcsS",
        "colab_type": "text"
      },
      "source": [
        "**Полагаю теорию можно считать успешной, результат улучшен, хоть и не значительно.**\n",
        "\n",
        "Мы улучшили лучший результат с прошлой таблицы на 1.5 тысячных процента) На кагле это бы сдвинуло нас на несколько десятков мест вперед! =) Не так уж плохо, для первого урока)))"
      ]
    }
  ]
}